{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from randVideo import VideoRenderer, VideoObject\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "from torchvision import transforms\n",
    "from preprocess_utensils import (\n",
    "    get_gray_image,\n",
    "    get_boundary_iou,\n",
    "    get_boundary_points,\n",
    "    uniform_sample_points,\n",
    ")\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import torch\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneHundredVideoGenerator(VideoRenderer):\n",
    "    def __init__(self, root=\"100Videos\") -> None:\n",
    "        super().__init__(root)\n",
    "    \n",
    "    def render_one_video(\n",
    "        self,\n",
    "        video_object: VideoObject,\n",
    "        index: int,\n",
    "        occulusion: bool = False,\n",
    "    ):\n",
    "        if occulusion:\n",
    "            video_name = video_object.name + \"_occlusion\"\n",
    "            self.occlusion_object.x = video_object.x\n",
    "            self.occlusion_object.y = video_object.y\n",
    "        else:\n",
    "            video_name = video_object.name\n",
    "        video_name = f\"{video_name}_{index}\"\n",
    "        path = f\"./tmp_videos/{self.root}/{video_name}\"\n",
    "        self.video_path_dict[video_name] = []\n",
    "\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        for i in range(20):\n",
    "            plt.figure()\n",
    "            ax = plt.gca()\n",
    "            plt.style.use(\"dark_background\")\n",
    "            video_object.random_move()\n",
    "            video_object.draw(ax)\n",
    "            if occulusion:\n",
    "                self.occlusion_object.random_move()\n",
    "                self.occlusion_object.draw(ax)\n",
    "            plt.xlim(-10, 10)\n",
    "            plt.ylim(-10, 10)\n",
    "            plt.axis(\"off\")\n",
    "            save_path = f\"{path}/{i:02d}.png\"\n",
    "            self.video_path_dict[video_name].append(save_path)\n",
    "            plt.savefig(save_path)\n",
    "            plt.close()\n",
    "    \n",
    "    def render_all_video(self):\n",
    "        for i in range(10):\n",
    "            for video_object in self.objects:\n",
    "                self.render_one_video(video_object, i, occulusion=False)\n",
    "                self.render_one_video(video_object, i, occulusion=True)\n",
    "\n",
    "generator = OneHundredVideoGenerator()\n",
    "generator.render_all_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ellipse_0', 'ellipse_occlusion_0', 'triangle_0', 'triangle_occlusion_0', 'rectangle_0', 'rectangle_occlusion_0', 'arrow_0', 'arrow_occlusion_0', 'fancybbox_0', 'fancybbox_occlusion_0', 'ellipse_1', 'ellipse_occlusion_1', 'triangle_1', 'triangle_occlusion_1', 'rectangle_1', 'rectangle_occlusion_1', 'arrow_1', 'arrow_occlusion_1', 'fancybbox_1', 'fancybbox_occlusion_1', 'ellipse_2', 'ellipse_occlusion_2', 'triangle_2', 'triangle_occlusion_2', 'rectangle_2', 'rectangle_occlusion_2', 'arrow_2', 'arrow_occlusion_2', 'fancybbox_2', 'fancybbox_occlusion_2', 'ellipse_3', 'ellipse_occlusion_3', 'triangle_3', 'triangle_occlusion_3', 'rectangle_3', 'rectangle_occlusion_3', 'arrow_3', 'arrow_occlusion_3', 'fancybbox_3', 'fancybbox_occlusion_3', 'ellipse_4', 'ellipse_occlusion_4', 'triangle_4', 'triangle_occlusion_4', 'rectangle_4', 'rectangle_occlusion_4', 'arrow_4', 'arrow_occlusion_4', 'fancybbox_4', 'fancybbox_occlusion_4', 'ellipse_5', 'ellipse_occlusion_5', 'triangle_5', 'triangle_occlusion_5', 'rectangle_5', 'rectangle_occlusion_5', 'arrow_5', 'arrow_occlusion_5', 'fancybbox_5', 'fancybbox_occlusion_5', 'ellipse_6', 'ellipse_occlusion_6', 'triangle_6', 'triangle_occlusion_6', 'rectangle_6', 'rectangle_occlusion_6', 'arrow_6', 'arrow_occlusion_6', 'fancybbox_6', 'fancybbox_occlusion_6', 'ellipse_7', 'ellipse_occlusion_7', 'triangle_7', 'triangle_occlusion_7', 'rectangle_7', 'rectangle_occlusion_7', 'arrow_7', 'arrow_occlusion_7', 'fancybbox_7', 'fancybbox_occlusion_7', 'ellipse_8', 'ellipse_occlusion_8', 'triangle_8', 'triangle_occlusion_8', 'rectangle_8', 'rectangle_occlusion_8', 'arrow_8', 'arrow_occlusion_8', 'fancybbox_8', 'fancybbox_occlusion_8', 'ellipse_9', 'ellipse_occlusion_9', 'triangle_9', 'triangle_occlusion_9', 'rectangle_9', 'rectangle_occlusion_9', 'arrow_9', 'arrow_occlusion_9', 'fancybbox_9', 'fancybbox_occlusion_9'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.video_path_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./tmp_videos/100Videos/video_path_dict.json\", \"w\") as f:\n",
    "    json.dump(generator.video_path_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneHundredRawset:\n",
    "    def __init__(self) -> None:\n",
    "        with open(\"./tmp_videos/100Videos/video_path_dict.json\", \"r\") as f:\n",
    "            self.video_path_dict = json.load(f)\n",
    "        self.video_names = list(self.video_path_dict.keys())\n",
    "        self.video_names.sort()\n",
    "        self.data_set = []\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "        for video_name in self.video_names:\n",
    "            self.data_set.append([])\n",
    "            for frame_path in self.video_path_dict[video_name]:\n",
    "                frame = Image.open(frame_path).convert(\"RGB\")\n",
    "                frame = self.transform(frame)\n",
    "                sgm = get_gray_image(frame_path)\n",
    "                boundary_points = get_boundary_points(sgm)\n",
    "                if boundary_points is None:\n",
    "                    boundary = torch.zeros((80, 2))\n",
    "                else:\n",
    "                    boundary = uniform_sample_points(boundary_points, 80)\n",
    "                    boundary = torch.tensor(boundary).int()\n",
    "                sgm[sgm > 0] = 1\n",
    "                sgm = torch.Tensor(sgm)\n",
    "                self.data_set[-1].append((frame, boundary, sgm))\n",
    "\n",
    "    def get_item(self, video_idx, frame_idx):\n",
    "        return self.data_set[video_idx][frame_idx]\n",
    "\n",
    "one_hundred_rawset = OneHundredRawset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tenLoader import TenDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hundred_dataset = TenDataset(one_hundred_rawset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
